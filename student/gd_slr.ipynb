{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b7586d88-1b36-42f6-9cf4-2d01cf6c5204",
   "metadata": {
    "id": "b7586d88-1b36-42f6-9cf4-2d01cf6c5204",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Quiz 1: Gradient Descent with Simple Linear Regression Using For Loop - Ronaldo Tineo\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    number-sections: true\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a8da5-27b2-4eef-84a0-70a354fcb50b",
   "metadata": {
    "id": "038a8da5-27b2-4eef-84a0-70a354fcb50b"
   },
   "source": [
    "## Tools and Libraries\n",
    "\n",
    "In this quiz, we will make use of:\n",
    "\n",
    "- **NumPy** - A fundamental library for scientific computing in Python, providing support for arrays, mathematical functions, and linear algebra operations\n",
    "- **Matplotlib** - A comprehensive library for creating static, animated, and interactive visualizations in Python\n",
    "- **Built-in Python functions** - Including `copy` for creating deep copies of objects and `math` for mathematical operations\n",
    "- **Jupyter notebook magic commands** - Such as `%matplotlib inline` for displaying plots inline and `%autoreload` for automatically reloading modules\n",
    "\n",
    "## Key Python Concepts Used\n",
    "- For loops for iterative computations\n",
    "- NumPy arrays for efficient numerical operations\n",
    "- Function definitions and parameter passing\n",
    "- Gradient descent algorithm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6cc0416-20b6-4d53-88ce-b45b6f0a4acb",
   "metadata": {
    "id": "a6cc0416-20b6-4d53-88ce-b45b6f0a4acb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153d9384-e918-4346-b704-fe59b219b57c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "153d9384-e918-4346-b704-fe59b219b57c",
    "outputId": "dce00b22-ea03-4f04-c4c1-0bb6a3208d29"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ed48f",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "### Real Estate Price Prediction Challenge\n",
    "\n",
    "Imagine you're a real estate analyst tasked with building a model to predict house prices based on square footage. You have access to a small but valuable dataset from recent sales in your area.\n",
    "\n",
    "**Our Dataset:**\n",
    "We have two recent home sales that will serve as our training data:\n",
    "\n",
    "| House | Size (1000 sqft) | Price (1000s of dollars) | Details |\n",
    "|-------|------------------|--------------------------|---------|\n",
    "| A     | 1.0              | 300                      | 1000 sqft â†’ $300,000 |\n",
    "| B     | 2.0              | 500                      | 2000 sqft â†’ $500,000 |\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this quiz, you will:\n",
    "\n",
    "1. **Implement from scratch** the three core components of gradient descent:\n",
    "   - Cost function computation\n",
    "   - Gradient calculation  \n",
    "   - Parameter optimization loop\n",
    "2. **Apply mathematical concepts** using Python for loops (no vectorization shortcuts!)\n",
    "3. **Visualize the learning process** through cost function plots\n",
    "4. **Make predictions** using your trained model\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Your mission is to find the optimal parameters $(w, b)$ for the linear model:\n",
    "$$f_{w,b}(x) = wx + b$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x$ = house size in thousands of square feet\n",
    "- $f_{w,b}(x)$ = predicted price in thousands of dollars\n",
    "- $w$ = slope (price increase per 1000 sqft)\n",
    "- $b$ = y-intercept (base price)\n",
    "\n",
    "**Question to ponder:** Looking at our data, can you estimate what the slope $w$ might be? What does this represent in real-world terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75428a4e-f708-4a61-9a56-288af4599b4a",
   "metadata": {
    "id": "75428a4e-f708-4a61-9a56-288af4599b4a"
   },
   "outputs": [],
   "source": [
    "# Create our data set\n",
    "x_train = np.array([1.0, 2.0])   #features\n",
    "y_train = np.array([300.0, 500.0])   #target value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba9a7b-7ee9-49fd-953a-e0fd1f7b2e0c",
   "metadata": {
    "id": "e3ba9a7b-7ee9-49fd-953a-e0fd1f7b2e0c"
   },
   "source": [
    "## Linear Regression Fundamentals\n",
    "\n",
    "In this quiz, you will fit the linear regression parameters $(w,b)$ to your dataset using gradient descent from scratch.\n",
    "\n",
    "### The Linear Model\n",
    "\n",
    "The model function for linear regression maps from input `x` (house size) to output `y` (house price):\n",
    "\n",
    "$$f_{w,b}(x) = wx + b$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $w$ is the **weight** (or slope) - how much the price changes per unit of size\n",
    "- $b$ is the **bias** (or y-intercept) - the base price when size = 0\n",
    "- $x$ is the input feature (house size in 1000s of sqft)\n",
    "- $f_{w,b}(x)$ is the predicted output (house price in 1000s of dollars)\n",
    "\n",
    "### Finding the Best Parameters\n",
    "\n",
    "To train a linear regression model, you need to find the optimal $(w,b)$ parameters:\n",
    "\n",
    "1. **Cost Function Evaluation**: Compare different parameter choices using a cost function $J(w,b)$\n",
    "   - $J(w,b)$ measures how well your model fits the data\n",
    "   - Lower cost = better fit\n",
    "   \n",
    "2. **Optimization Goal**: Find $(w,b)$ that minimizes $J(w,b)$\n",
    "   - The \"best\" parameters are those with the smallest cost\n",
    "   - This gives you the line that best fits your training data\n",
    "\n",
    "3. **Gradient Descent**: Use this iterative algorithm to find optimal parameters\n",
    "   - Start with initial guesses for $w$ and $b$\n",
    "   - Repeatedly adjust parameters in the direction that reduces cost\n",
    "   - Each step moves closer to the optimal values\n",
    "\n",
    "### The Power of Your Model\n",
    "\n",
    "Once trained, your linear regression model becomes a **prediction machine**:\n",
    "\n",
    "- **Input**: Square footage of any house\n",
    "- **Output**: Estimated selling price\n",
    "- **Application**: Help real estate agents, buyers, and sellers make informed decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817cde90-255a-4bf0-945a-a904c5008e84",
   "metadata": {
    "id": "817cde90-255a-4bf0-945a-a904c5008e84"
   },
   "source": [
    "## Implement Gradient Descent From Scratch\n",
    "\n",
    "Now comes the exciting part! You will implement the gradient descent algorithm step by step using **for loops only** - no vectorized operations allowed. This approach will help you understand exactly what's happening at each step.\n",
    "\n",
    "### The Three Essential Functions\n",
    "\n",
    "You'll build three interconnected functions that work together:\n",
    "\n",
    "1. **`compute_cost`** - Measures how well your current parameters fit the data\n",
    "2. **`compute_gradient`** - Calculates which direction to adjust your parameters  \n",
    "3. **`gradient_descent`** - Orchestrates the iterative optimization process\n",
    "\n",
    "### Function Overview\n",
    "\n",
    "   ```\n",
    "   Input: Training Data (x, y)\n",
    "      â†“\n",
    "   compute_cost(w, b) â†’ Current fit quality\n",
    "      â†“\n",
    "   compute_gradient(w, b) â†’ Direction to improve\n",
    "      â†“  \n",
    "   gradient_descent() â†’ New improved (w, b)\n",
    "      â†“\n",
    "   Repeat until convergence!\n",
    "   ```\n",
    "\n",
    "### Implementation Strategy\n",
    "\n",
    "**Why for loops?** While NumPy vectorization is faster, using explicit loops helps you:\n",
    "\n",
    "- Understand each calculation step-by-step\n",
    "- Build intuition for how gradient descent actually works\n",
    "- Appreciate vectorization when you use it later!\n",
    "\n",
    "### Coding Conventions\n",
    "\n",
    "To keep our code readable and mathematically accurate:\n",
    "\n",
    "- **Partial derivatives**: Variables representing $\\frac{\\partial J(w,b)}{\\partial b}$ will be named `dj_db`\n",
    "- **Naming pattern**: `dj_d[parameter]` where `[parameter]` is the variable we're taking the derivative with respect to\n",
    "- **Abbreviation**: \"w.r.t\" = \"With Respect To\" (common mathematical shorthand)\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- $\\frac{\\partial J(w,b)}{\\partial w}$ â†’ `dj_dw` (derivative of J with respect to w)  \n",
    "- $\\frac{\\partial J(w,b)}{\\partial b}$ â†’ `dj_db` (derivative of J with respect to b)\n",
    "\n",
    "### Ready to Code?\n",
    "\n",
    "Let's implement each function one by one, building your gradient descent algorithm from the ground up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7777fd-33b5-43ef-b973-3bcd3f89141b",
   "metadata": {
    "id": "3c7777fd-33b5-43ef-b973-3bcd3f89141b"
   },
   "source": [
    "### Function 1: Compute_Cost\n",
    "\n",
    "The cost function is your **quality meter** - it tells you how well your current parameters $(w,b)$ fit the training data. Lower cost means better fit!\n",
    "\n",
    "#### Understanding the Cost Function\n",
    "\n",
    "The Mean Squared Error (MSE) cost function measures the average squared difference between predictions and actual values:\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "**Breaking it down:**\n",
    "\n",
    "- $f_{w,b}(x^{(i)}) = wx^{(i)} + b$ â†’ Your model's prediction for house $i$\n",
    "- $y^{(i)}$ â†’ Actual selling price for house $i$  \n",
    "- $(f_{w,b}(x^{(i)}) - y^{(i)})^2$ â†’ Squared error for house $i$\n",
    "- $\\frac{1}{2m}$ â†’ Average over all $m$ examples (the $\\frac{1}{2}$ simplifies calculus later!)\n",
    "\n",
    "#### Task 1: compute the cost\n",
    "\n",
    "Complete the `compute_cost` function using for loops to:\n",
    "\n",
    "**Step 1:** For each training example $i$, compute:\n",
    "\n",
    "- **Prediction:** $f_{wb}(x^{(i)}) = wx^{(i)} + b$\n",
    "- **Individual cost:** $cost^{(i)} = (f_{wb}(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "**Step 2:** Sum all individual costs and return the total:\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} cost^{(i)}$$\n",
    "\n",
    "**Key insight:** You're measuring how \"wrong\" your predictions are on average. The squaring ensures:\n",
    "\n",
    "- All errors are positive (no cancellation between over/under predictions)\n",
    "- Larger errors are penalized more heavily than small errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aed6956-9545-48f9-8d7a-644c1cc1d35e",
   "metadata": {
    "id": "9aed6956-9545-48f9-8d7a-644c1cc1d35e"
   },
   "outputs": [],
   "source": [
    "# compute_cost\n",
    "\n",
    "def compute_cost(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the cost function for linear regression using Mean Squared Error.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Shape (m,) - Input features (house sizes in 1000s sqft)\n",
    "        y (ndarray): Shape (m,) - Target values (house prices in 1000s dollars)\n",
    "        w (scalar): Weight parameter (slope of the line)\n",
    "        b (scalar): Bias parameter (y-intercept of the line)\n",
    "\n",
    "    Returns:\n",
    "        total_cost (float): The cost J(w,b) representing how well the parameters\n",
    "                           fit the training data. Lower cost = better fit.\n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m = x.shape[0]\n",
    "\n",
    "    # Initialize total cost\n",
    "    total_cost = 0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Variable to accumulate the sum of squared errors\n",
    "    cost_sum = 0\n",
    "    \n",
    "    # Loop through each training example\n",
    "    for i in range(m):\n",
    "        \n",
    "        # Step 1: Calculate prediction using linear model\n",
    "        f_wb = w*x[i] + b \n",
    "        \n",
    "        # Step 2: Calculate squared error for this example\n",
    "        error = f_wb - y[i]\n",
    "        cost = error ** 2\n",
    "        \n",
    "        # Step 3: Add this example's cost to running sum\n",
    "        cost_sum = cost_sum + cost\n",
    "    \n",
    "    # Step 4: Calculate final cost using MSE \n",
    "    total_cost = (1/(2*m)) * cost_sum\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad95f76-8295-423b-9337-594bc7fc8c73",
   "metadata": {
    "id": "dad95f76-8295-423b-9337-594bc7fc8c73"
   },
   "source": [
    "#### Test Your Implementation\n",
    "\n",
    "Great job! Now let's verify that your `compute_cost` function works correctly. \n",
    "\n",
    "Run the test code below to check your implementation. The test uses initial parameters `w=2` and `b=1` to see how well they fit our training data.\n",
    "\n",
    "**What to expect:**\n",
    "\n",
    "- The function should return a `float` type\n",
    "- The cost value tells you how well these parameters fit the data\n",
    "- Higher cost = worse fit, Lower cost = better fit\n",
    "\n",
    "**For the Canvas quiz:** Record the exact cost value that your function returns - you'll need this number to complete the quiz questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69e4ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "Cost at initial w: 83308.500\n"
     ]
    }
   ],
   "source": [
    "# Compute cost with some initial values for paramaters w, b\n",
    "initial_w = 2\n",
    "initial_b = 1\n",
    "\n",
    "cost = compute_cost(x_train, y_train, initial_w, initial_b)\n",
    "print(type(cost))\n",
    "print(f'Cost at initial w: {cost:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01902b",
   "metadata": {},
   "source": [
    "### Function 2: Compute_Gradient\n",
    "\n",
    "The gradient tells you **which direction to move** your parameters to reduce the cost. Think of it as a compass pointing toward better parameter values!\n",
    "\n",
    "#### Understanding Gradients\n",
    "\n",
    "Gradients are partial derivatives that measure how the cost function changes when you slightly adjust each parameter:\n",
    "\n",
    "- $\\frac{\\partial J(w,b)}{\\partial w}$ â†’ How much does cost change if we increase $w$ slightly?\n",
    "- $\\frac{\\partial J(w,b)}{\\partial b}$ â†’ How much does cost change if we increase $b$ slightly?\n",
    "\n",
    "**The math behind it:** For our cost function $J(w,b) = \\frac{1}{2m} \\sum (f_{w,b}(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "The partial derivatives work out to:\n",
    "$$\\frac{\\partial J(w,b)}{\\partial b}^{(i)} = (f_{w,b}(x^{(i)}) - y^{(i)})$$\n",
    "$$\\frac{\\partial J(w,b)}{\\partial w}^{(i)} = (f_{w,b}(x^{(i)}) - y^{(i)}) \\cdot x^{(i)}$$\n",
    "\n",
    "#### Task 2: compute the gradient\n",
    "\n",
    "Complete the `compute_gradient` function using for loops to:\n",
    "\n",
    "**Step 1:** For each training example $i$, compute:\n",
    "\n",
    "- **Prediction:** $f_{wb}(x^{(i)}) = wx^{(i)} + b$\n",
    "- **Error:** $error^{(i)} = f_{wb}(x^{(i)}) - y^{(i)}$ \n",
    "- **Gradient contributions:**\n",
    "  - For $b$: $\\frac{\\partial J}{\\partial b}^{(i)} = error^{(i)}$\n",
    "  - For $w$: $\\frac{\\partial J}{\\partial w}^{(i)} = error^{(i)} \\cdot x^{(i)}$\n",
    "\n",
    "**Step 2:** Average all gradient contributions:\n",
    "$$\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{m} \\sum\\limits_{i=0}^{m-1} \\frac{\\partial J}{\\partial b}^{(i)}$$\n",
    "$$\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{m} \\sum\\limits_{i=0}^{m-1} \\frac{\\partial J}{\\partial w}^{(i)}$$\n",
    "\n",
    "**Key insight:** \n",
    "\n",
    "- **Positive gradient** â†’ Increase parameter to reduce cost\n",
    "- **Negative gradient** â†’ Decrease parameter to reduce cost  \n",
    "- **Larger magnitude** â†’ Steeper slope, bigger adjustment needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64ddb976-e672-4c7c-bf17-7f5f3b9b459f",
   "metadata": {
    "id": "64ddb976-e672-4c7c-bf17-7f5f3b9b459f"
   },
   "outputs": [],
   "source": [
    "# compute_gradient\n",
    "def compute_gradient(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (m,) Input to the model (house sizes)\n",
    "      y (ndarray): Shape (m,) Label (house prices)\n",
    "      w, b (scalar): Parameters of the model\n",
    "    Returns\n",
    "      dj_dw (scalar): The gradient of the cost w.r.t. the parameter w\n",
    "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b\n",
    "     \"\"\"\n",
    "\n",
    "    # Number of training examples\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    # Initialize gradient accumulators\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Loop through each training example\n",
    "    for i in range(m):\n",
    "        \n",
    "        # Step 1: Calculate prediction for example i\n",
    "        f_wb = w*x[i] + b \n",
    "        \n",
    "        # Step 2: Calculate the error (prediction - actual)\n",
    "        error = f_wb - y[i]\n",
    "        \n",
    "        # Step 3: Calculate gradient contributions for this example\n",
    "        dj_db_i = error \n",
    "        \n",
    "        dj_dw_i = error * x[i]\n",
    "        \n",
    "        # Step 4: Accumulate the gradients\n",
    "        dj_db += dj_db_i\n",
    "        dj_dw += dj_dw_i\n",
    "    \n",
    "    # Step 5: Average the gradients over all examples\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e24e3-1fce-469f-97ef-9a63a9ca9254",
   "metadata": {
    "id": "d58e24e3-1fce-469f-97ef-9a63a9ca9254"
   },
   "source": [
    "#### Test Your Gradient Function\n",
    "\n",
    "Excellent work! Now let's test your `compute_gradient` function to see if it correctly calculates the gradients.\n",
    "\n",
    "Run the test below to verify your implementation. We'll start with parameters `w=0` and `b=0` to see what gradients your function computes.\n",
    "\n",
    "**What to expect:**\n",
    "\n",
    "- The function should return two values: `dj_dw` and `dj_db`\n",
    "- These represent the direction and magnitude to adjust each parameter\n",
    "- The values tell you how to improve your model's fit to the data\n",
    "\n",
    "**For the Canvas quiz:** Record the exact gradient values that your function returns - you'll need these numbers for the quiz questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a8cd99-37b3-46e8-bad9-c8194fadf8a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33a8cd99-37b3-46e8-bad9-c8194fadf8a9",
    "outputId": "41ef6c10-376f-4d7f-a8a6-b7eac22013a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at initial w, b (zeros): -650.0 -400.0\n"
     ]
    }
   ],
   "source": [
    "# Compute and display gradient with w and b initialized to zeroes\n",
    "initial_w = 0\n",
    "initial_b = 0\n",
    "\n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, initial_w, initial_b)\n",
    "print('Gradient at initial w, b (zeros):', tmp_dj_dw, tmp_dj_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d647d55",
   "metadata": {},
   "source": [
    "### Function 3: Do Gradient Decent\n",
    "\n",
    "After you implemented `compute_gradient` which calculates $\\frac{\\partial J(w)}{\\partial w}$, $\\frac{\\partial J(w)}{\\partial b}$ , you will next implement the gradient descent for parameters $w, b$ for linear regression.\n",
    "\n",
    "As described in the lecture, the gradient descent algorithm is:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \\phantom {0000} b := b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b} \\newline       \\; & \\phantom {0000} w := w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w}   \\; &\n",
    "\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "where, parameters $w, b$ are both updated simultaniously and where  \n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)} \n",
    "$$\n",
    "\n",
    "* $m$ is the number of training examples in the dataset\n",
    "\n",
    "    \n",
    "*  $f_{w,b}(x^{(i)})$ is the model's prediction, while $y^{(i)}$, is the target value\n",
    "a.lgorithm.\n",
    "\n",
    "#### Task 3: do gradient descent\n",
    "\n",
    "Please complete the `gradient_descent` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddf8d754-3045-4492-908b-9f74df6c70fd",
   "metadata": {
    "id": "ddf8d754-3045-4492-908b-9f74df6c70fd"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to optimize parameters w and b\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray): Shape (m,) - Input features (house sizes)\n",
    "      y (ndarray): Shape (m,) - Target values (house prices)  \n",
    "      w_in, b_in (scalar): Initial parameter values\n",
    "      cost_function: Function to compute cost J(w,b)\n",
    "      gradient_function: Function to compute gradients dJ/dw, dJ/db\n",
    "      alpha (float): Learning rate - how big steps to take\n",
    "      num_iters (int): Number of iterations to run\n",
    "    Returns:\n",
    "      w, b (scalar): Optimized parameter values\n",
    "      J_history (list): Cost at each iteration (for plotting)\n",
    "      w_history (list): Parameter values at each iteration (for plotting)\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of training examples\n",
    "    m = len(x)\n",
    "    \n",
    "    # Arrays to store history for plotting learning curves\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    # Initialize parameters (make copies to avoid modifying inputs)\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Main gradient descent loop\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        # Step 1: Compute gradients using your gradient function\n",
    "        dj_dw, dj_db = compute_gradient(x, y, w, b)\n",
    "        \n",
    "        # Step 2: Update parameters using gradient descent rule\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "        # Step 3: Compute and save cost for this iteration (for plotting)\n",
    "        if i < 100000:  # Prevent memory issues for very long runs\n",
    "            cost = cost_function(x, y, w, b)\n",
    "            J_history.append(cost)\n",
    "            w_history.append([w, b])\n",
    "        \n",
    "        # Print progress every 10% of iterations\n",
    "        if i % math.ceil(num_iters/10) == 0:\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f} \",\n",
    "                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
    "                  f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return w, b, J_history, w_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48d490-3ec7-4ade-8c81-5fc561aadc0f",
   "metadata": {
    "id": "ee48d490-3ec7-4ade-8c81-5fc561aadc0f"
   },
   "source": [
    "\n",
    "####  Find Your Optimal Parameters via your gradient descent\n",
    "\n",
    "Now let's run your gradient descent algorithm to discover the optimal values of $w$ and $b$ for our real estate dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e0951a1-073d-4895-9bb1-3b7668e2cde3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e0951a1-073d-4895-9bb1-3b7668e2cde3",
    "outputId": "22154047-5730-4eac-a25a-d887ab7ed8a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 79274.81  dj_dw: -6.500e+02, dj_db: -4.000e+02   w:  6.500e+00, b: 4.00000e+00\n",
      "Iteration 1000: Cost     3.41  dj_dw: -3.712e-01, dj_db:  6.007e-01   w:  1.949e+02, b: 1.08228e+02\n",
      "Iteration 2000: Cost     0.79  dj_dw: -1.789e-01, dj_db:  2.895e-01   w:  1.975e+02, b: 1.03966e+02\n",
      "Iteration 3000: Cost     0.18  dj_dw: -8.625e-02, dj_db:  1.396e-01   w:  1.988e+02, b: 1.01912e+02\n",
      "Iteration 4000: Cost     0.04  dj_dw: -4.158e-02, dj_db:  6.727e-02   w:  1.994e+02, b: 1.00922e+02\n",
      "Iteration 5000: Cost     0.01  dj_dw: -2.004e-02, dj_db:  3.243e-02   w:  1.997e+02, b: 1.00444e+02\n",
      "Iteration 6000: Cost     0.00  dj_dw: -9.660e-03, dj_db:  1.563e-02   w:  1.999e+02, b: 1.00214e+02\n",
      "Iteration 7000: Cost     0.00  dj_dw: -4.657e-03, dj_db:  7.535e-03   w:  1.999e+02, b: 1.00103e+02\n",
      "Iteration 8000: Cost     0.00  dj_dw: -2.245e-03, dj_db:  3.632e-03   w:  2.000e+02, b: 1.00050e+02\n",
      "Iteration 9000: Cost     0.00  dj_dw: -1.082e-03, dj_db:  1.751e-03   w:  2.000e+02, b: 1.00024e+02\n",
      "w,b found by gradient descent: 199.99285075131766 100.011567727362\n"
     ]
    }
   ],
   "source": [
    "# initialize fitting parameters. Recall that the shape of w is (n,)\n",
    "initial_w = 0.\n",
    "initial_b = 0.\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 10000\n",
    "alpha = 0.01\n",
    "\n",
    "w, b, J_hist, p_hist = gradient_descent(x_train ,y_train, initial_w, initial_b,\n",
    "                     compute_cost, compute_gradient, alpha, iterations)\n",
    "print(\"w,b found by gradient descent:\", w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b7112-7a06-481e-8daf-f0852fd885ec",
   "metadata": {
    "id": "867b7112-7a06-481e-8daf-f0852fd885ec"
   },
   "source": [
    "## ðŸ“ˆ Visualizing the Learning Process: Cost Function Evolution\n",
    "\n",
    "### Understanding Your Algorithm's Journey\n",
    "\n",
    "Now comes one of the most exciting parts - watching your gradient descent algorithm learn in real time! The learning curve visualization will show you exactly how your algorithm improved with each iteration.\n",
    "\n",
    "### What You'll Observe in the Plots\n",
    "\n",
    "**Two-Panel Visualization:**\n",
    "\n",
    "1. **Left Panel (Early Learning):** Shows the first 100 iterations\n",
    "   \n",
    "   - **Expect:** Sharp, rapid decrease in cost\n",
    "   - **Why:** Initial parameter values are far from optimal, so big improvements happen quickly\n",
    "   - **Learning:** This demonstrates the power of gradient descent's initial convergence\n",
    "\n",
    "2. **Right Panel (Fine-Tuning):** Shows iterations 1000+ to the end\n",
    "   \n",
    "   - **Expect:** Gradual, steady decrease approaching a minimum\n",
    "   - **Why:** Algorithm is fine-tuning parameters near the optimal solution\n",
    "   - **Learning:** Shows how gradient descent achieves precision through patience\n",
    "\n",
    "### Key Learning Insights\n",
    "\n",
    "**Cost Decrease Patterns:**\n",
    "\n",
    "- **Steep drop** â†’ Your algorithm is making big improvements (far from optimum)\n",
    "- **Gradual decline** â†’ Fine-tuning phase (approaching optimum)  \n",
    "- **Plateau** â†’ Convergence achieved (found the minimum!)\n",
    "\n",
    "**What This Tells You:**\n",
    "\n",
    "- **Algorithm Health:** Consistently decreasing cost = healthy learning\n",
    "- **Learning Rate Quality:** Smooth curves = good learning rate choice\n",
    "- **Convergence Status:** Flattening curve = approaching optimal solution\n",
    "\n",
    "**For the Canvas Quiz:** Pay attention to the final cost value and how many iterations it took to converge - these observations may be part of your quiz questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41184459-21ed-4bbb-a371-24409929c056",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "41184459-21ed-4bbb-a371-24409929c056",
    "outputId": "993fe0ea-76e5-4126-851b-0571db16486c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost versus iteration\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12,4))\n",
    "ax1.plot(J_hist[:100])\n",
    "ax2.plot(1000 + np.arange(len(J_hist[1000:])), J_hist[1000:])\n",
    "ax1.set_title(\"Cost vs. iteration(start)\");  ax2.set_title(\"Cost vs. iteration (end)\")\n",
    "ax1.set_ylabel('Cost')            ;  ax2.set_ylabel('Cost')\n",
    "ax1.set_xlabel('iteration step')  ;  ax2.set_xlabel('iteration step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a840ee-f302-4c1d-8f31-b79518f24ee7",
   "metadata": {
    "id": "90a840ee-f302-4c1d-8f31-b79518f24ee7"
   },
   "source": [
    "##  Making Predictions with Your Trained Model\n",
    "\n",
    "### Task 4: Real Estate Price Prediction Challenge\n",
    "\n",
    "**The Moment of Truth!** \n",
    "Now that you have trained your model and found optimal parameters $w$ and $b$, it's time to put your **prediction machine** to work! This is where all your hard work pays off.\n",
    "\n",
    "### Understanding Your Prediction Tool\n",
    "\n",
    "**The Prediction Formula:**\n",
    "Your linear regression model makes predictions using the simple but powerful equation:\n",
    "\n",
    "$$ f_{w,b}(x^{(i)}) = wx^{(i)} + b$$\n",
    "\n",
    "**Breaking Down Each Component:**\n",
    "\n",
    "- **$w$ (slope)** = Price increase per 1000 sqft â†’ *\"How much more does each additional 1000 sqft cost?\"*\n",
    "- **$b$ (y-intercept)** = Base price when size = 0 â†’ *\"What's the starting price before considering square footage?\"*\n",
    "- **$x^{(i)}$ (input)** = House size in thousands of sqft â†’ *\"The feature we're using to predict\"*\n",
    "- **$f_{w,b}(x^{(i)})$ (output)** = Predicted price in thousands of dollars â†’ *\"Our model's best guess\"*\n",
    "\n",
    "###  Your Real Estate Consultation Challenge\n",
    "\n",
    "**The Scenario:**\n",
    "\n",
    "A potential buyer walks into your real estate office and asks:\n",
    "\n",
    "> *\"I'm interested in buying a house with exactly **1200 square feet**. Based on recent market data, what should I expect to pay?\"*\n",
    "\n",
    "**Your Mission:**\n",
    "\n",
    "1. **Use your trained parameters** $(w, b)$ found by gradient descent\n",
    "2. **Convert units properly** (1200 sqft â†’ thousands of sqft)\n",
    "3. **Calculate the prediction** using your linear model\n",
    "4. **Provide a professional estimate** to your client\n",
    "\n",
    "\n",
    "**For the Canvas Quiz:** ðŸ“ Record your predicted price carefully - you'll need this exact number for the quiz questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "SF2ScjY1RYJ8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF2ScjY1RYJ8",
    "outputId": "6c2211ce-6bba-4eae-c560-ad7e3203d795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for a house with 1200 sqft: 340003\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "# House size: 1200 sqft\n",
    "f_wb = w * 1.2 + b\n",
    "\n",
    "print(f\"Prediction for a house with 1200 sqft: {f_wb*1000:.0f}\")\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ccd1ed",
   "metadata": {},
   "source": [
    "##  Bonus Exploration: Learning Rate Sensitivity Analysis\n",
    "\n",
    "**Experiment Goal:** Run the following code cells and investigate how different learning rates affect gradient descent convergence and performance\n",
    "\n",
    "###  The Learning Rate Experiment\n",
    "\n",
    "Learning rate (Î±) is one of the most critical hyperparameters in machine learning. This experiment will demonstrate how this single parameter can dramatically affect your algorithm's behavior, convergence speed, and final performance.\n",
    "\n",
    "###  Experimental Design\n",
    "\n",
    "**Test Parameters:**\n",
    "- Learning rates: 0.001, 0.01, 0.1, 0.5\n",
    "- Iterations: 1000 (sufficient to observe different behaviors)\n",
    "- Initial conditions: w=0, b=0 (same for all tests)\n",
    "- Metric: Cost function evolution over time\n",
    "\n",
    "**Hypothesis:** Different learning rates will show distinct convergence patterns - some too slow, some too fast, and hopefully one \"just right\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using different learning rates to compare convergence behavior\n",
    "# This helps understand how learning rate affects training dynamics\n",
    "\n",
    "# Define different learning rates to test\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "iterations = 1000\n",
    "\n",
    "# Store results for each learning rate\n",
    "results = {}\n",
    "\n",
    "print(\"Testing different learning rates:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, alpha in enumerate(learning_rates):\n",
    "    print(f\"\\nTesting learning rate: {alpha}\")\n",
    "    \n",
    "    # Reset initial parameters for fair comparison\n",
    "    initial_w = 0.0\n",
    "    initial_b = 0.0\n",
    "    \n",
    "    # Run gradient descent with current learning rate\n",
    "    w_final, b_final, J_history, p_history = gradient_descent(\n",
    "        x_train, y_train, initial_w, initial_b, \n",
    "        compute_cost, compute_gradient, alpha, iterations\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    results[alpha] = {\n",
    "        'w': w_final,\n",
    "        'b': b_final,\n",
    "        'cost_history': J_history,\n",
    "        'final_cost': J_history[-1] if J_history else float('inf')\n",
    "    }\n",
    "    \n",
    "    print(f\"Final parameters: w={w_final:.6f}, b={b_final:.6f}\")\n",
    "    print(f\"Final cost: {J_history[-1]:.8f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Learning Rate Comparison Summary:\")\n",
    "for alpha in learning_rates:\n",
    "    result = results[alpha]\n",
    "    print(f\"Î± = {alpha:5.3f}: Final Cost = {result['final_cost']:.8f}, w = {result['w']:.6f}, b = {result['b']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3183e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization of learning curves\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: All learning curves together (full range)\n",
    "ax1.set_title('Learning Curves: All Learning Rates (Full Range)', fontsize=14, fontweight='bold')\n",
    "for i, alpha in enumerate(learning_rates):\n",
    "    cost_history = results[alpha]['cost_history']\n",
    "    ax1.plot(cost_history, color=colors[i], label=f'Î± = {alpha}', linewidth=2)\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Cost J(w,b)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Early iterations (first 100) - shows initial convergence behavior\n",
    "ax2.set_title('Early Learning Phase (First 100 Iterations)', fontsize=14, fontweight='bold')\n",
    "for i, alpha in enumerate(learning_rates):\n",
    "    cost_history = results[alpha]['cost_history']\n",
    "    early_history = cost_history[:min(100, len(cost_history))]\n",
    "    ax2.plot(early_history, color=colors[i], label=f'Î± = {alpha}', linewidth=2)\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Cost J(w,b)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Log scale view - better for comparing convergence rates\n",
    "ax3.set_title('Learning Curves (Log Scale) - Convergence Analysis', fontsize=14, fontweight='bold')\n",
    "for i, alpha in enumerate(learning_rates):\n",
    "    cost_history = results[alpha]['cost_history']\n",
    "    # Add small epsilon to avoid log(0) issues\n",
    "    log_costs = [max(cost, 1e-10) for cost in cost_history]\n",
    "    ax3.semilogy(log_costs, color=colors[i], label=f'Î± = {alpha}', linewidth=2)\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Cost J(w,b) (Log Scale)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Final cost comparison (bar chart)\n",
    "ax4.set_title('Final Cost Comparison After 1000 Iterations', fontsize=14, fontweight='bold')\n",
    "final_costs = [results[alpha]['final_cost'] for alpha in learning_rates]\n",
    "bars = ax4.bar(range(len(learning_rates)), final_costs, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax4.set_xlabel('Learning Rate')\n",
    "ax4.set_ylabel('Final Cost')\n",
    "ax4.set_xticks(range(len(learning_rates)))\n",
    "ax4.set_xticklabels([f'Î± = {alpha}' for alpha in learning_rates])\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, cost) in enumerate(zip(bars, final_costs)):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(final_costs)*0.01, \n",
    "             f'{cost:.6f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis and insights\n",
    "print(\"\\nðŸ” LEARNING RATE ANALYSIS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find best performing learning rate\n",
    "best_alpha = min(learning_rates, key=lambda x: results[x]['final_cost'])\n",
    "worst_alpha = max(learning_rates, key=lambda x: results[x]['final_cost'])\n",
    "\n",
    "print(f\"ðŸ† BEST Learning Rate: Î± = {best_alpha}\")\n",
    "print(f\"   Final Cost: {results[best_alpha]['final_cost']:.8f}\")\n",
    "print(f\"   Parameters: w = {results[best_alpha]['w']:.6f}, b = {results[best_alpha]['b']:.6f}\")\n",
    "\n",
    "print(f\"\\nâŒ WORST Learning Rate: Î± = {worst_alpha}\")\n",
    "print(f\"   Final Cost: {results[worst_alpha]['final_cost']:.8f}\")\n",
    "print(f\"   Parameters: w = {results[worst_alpha]['w']:.6f}, b = {results[worst_alpha]['b']:.6f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "print(\"   â€¢ Lower learning rates â†’ More stable but slower convergence\")\n",
    "print(\"   â€¢ Higher learning rates â†’ Faster initial progress but may overshoot\")\n",
    "print(\"   â€¢ Optimal learning rate balances speed and stability\")\n",
    "print(\"   â€¢ Learning rate choice significantly impacts training efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c009e",
   "metadata": {},
   "source": [
    "###  Your Insights and Reflection\n",
    "\n",
    "**Analyze the results above and answer these questions:**\n",
    "\n",
    "####  Observation Questions:\n",
    "\n",
    "1. **Which learning rate achieved the lowest final cost? Why do you think this happened?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "   \n",
    "2. **Compare the convergence speed between Î±=0.001 and Î±=0.1. What trade-offs do you observe?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "   \n",
    "3. **Looking at the early convergence plot (first 100 iterations), which learning rate made the most dramatic initial progress? Was this rate also the best overall performer?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "\n",
    "####  Critical Thinking Questions:\n",
    "\n",
    "4. **If you had to choose ONE learning rate for a production machine learning system, which would you choose and why?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "\n",
    "5. **What would you expect to happen if we tested an even larger learning rate like Î±=1.0? Explain your reasoning.**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "\n",
    "6. **How might the optimal learning rate change if we had:**\n",
    "   - A much larger dataset (1000s of examples)?\n",
    "   - A more complex cost function landscape?\n",
    "   \n",
    "   *Your answers:*\n",
    "   \n",
    "\n",
    "####  Real-World Application:\n",
    "\n",
    "7. **You're a data scientist at a real estate company. Based on this experiment, what would you tell your manager about the importance of learning rate tuning?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "Write 3-5 bullet points summarizing the most important lessons from this learning rate sensitivity analysis:\n",
    "\n",
    "- *Your takeaway 1:*\n",
    "- *Your takeaway 2:*  \n",
    "- *Your takeaway 3:*\n",
    "- *Your takeaway 4:*\n",
    "- *Your takeaway 5:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344729aa-f0e6-4910-b08a-c0c667c964fc",
   "metadata": {
    "id": "344729aa-f0e6-4910-b08a-c0c667c964fc"
   },
   "source": [
    "## ðŸ† Congratulations! You've Mastered Gradient Descent!\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this quiz, you successfully:\n",
    "\n",
    "**ðŸ”¬ Built from Scratch:**\n",
    "\n",
    "- Cost function using Mean Squared Error\n",
    "- Gradient calculations with partial derivatives  \n",
    "- Complete gradient descent optimization algorithm\n",
    "\n",
    "**ðŸ  Solved Real Problems:**\n",
    "\n",
    "- Predicted house prices using machine learning\n",
    "- Trained a model on actual data\n",
    "- Made business-ready predictions\n",
    "\n",
    "**ðŸ“Š Understood the Process:**\n",
    "\n",
    "- Visualized algorithm learning through cost plots\n",
    "- Observed parameter convergence in real-time\n",
    "- Connected math to practical applications\n",
    "\n",
    "\n",
    "### Next Steps in Your Learning Journey\n",
    "\n",
    "You're now ready for:\n",
    "\n",
    "- **Multi-variable regression** and beyond!\n",
    "- **Vectorized implementations** for better performance\n",
    "- **Advanced algorithms** (Adam, RMSprop, etc.)\n",
    "\n",
    "\n",
    "**Key Insight:** Every advanced ML algorithm builds on these fundamentals you've mastered!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfdab3-e6d8-426f-8699-cd01f763d538",
   "metadata": {
    "id": "1dcfdab3-e6d8-426f-8699-cd01f763d538"
   },
   "source": [
    "## Reference\n",
    "\n",
    "https://www.deeplearning.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f328376-71d5-46af-883d-06d9feba7383",
   "metadata": {
    "id": "0f328376-71d5-46af-883d-06d9feba7383"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
